{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4961e54c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4961e54c",
        "outputId": "d1aad023-a9b0-419e-f50b-bf89bc7e6880"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XggC9GYztTBl",
      "metadata": {
        "id": "XggC9GYztTBl"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/AarohiSingla/Tracking-and-counting-Using-YOLOv8-and-DeepSORT.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdxWfbMPtfqK",
      "metadata": {
        "id": "bdxWfbMPtfqK"
      },
      "outputs": [],
      "source": [
        "!cd Tracking-and-counting-Using-YOLOv8-and-DeepSORT\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5ea3ead0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5ea3ead0",
        "outputId": "004a7126-2ba0-4c7b-b22b-40f0015beb5a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\MANAK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'8.0.221'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import ultralytics\n",
        "ultralytics.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6801a5a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6801a5a9",
        "outputId": "dd3d8b81-172e-4893-8168-569dc2fe177a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.10.0+cpu'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9627ba4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "9627ba4a",
        "outputId": "fffeca46-58ac-41da-f565-ae9c046921a5"
      },
      "outputs": [],
      "source": [
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30beac26",
      "metadata": {
        "id": "30beac26"
      },
      "source": [
        "# Detect, track and count Persons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c23349aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c23349aa",
        "outputId": "f48d1b44-1328-444b-89eb-2a56efd27efd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 2] The system cannot find the file specified: 'Tracking-and-counting-Using-YOLOv8-and-DeepSORT'\n",
            "c:\\Users\\MANAK\\Desktop\\CES751PROJ\\Tracking-and-counting-Using-YOLOv8-and-DeepSORT\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\MANAK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\magics\\osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
            "  bkms = self.shell.db.get('bookmarks', {})\n"
          ]
        }
      ],
      "source": [
        "%cd Tracking-and-counting-Using-YOLOv8-and-DeepSORT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7ac57944",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ac57944",
        "outputId": "c4ab0fed-bf31-4114-fbb2-4182af08d078"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\MANAK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 c:\\Users\\MANAK\\Desktop\\CES751PROJ\\Tracking-and-counting-Using-YOLOv8-and-DeepSORT\\car.jpg: 288x640 1 car, 140.0ms\n",
            "Speed: 13.5ms preprocess, 140.0ms inference, 15.7ms postprocess per image at shape (1, 3, 288, 640)\n",
            "Results saved to \u001b[1mruns\\detect\\predict12\u001b[0m\n",
            "[2.0]\n",
            "Class: car\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "import time\n",
        "import torch\n",
        "import cv2\n",
        "import torch.backends.cudnn as cudnn\n",
        "from PIL import Image\n",
        "import colorsys\n",
        "import numpy as np\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "results = model(\"car.jpg\", save=True)\n",
        "\n",
        "\n",
        "\n",
        "class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
        "\n",
        "for result in results:\n",
        "    boxes = result.boxes  # Boxes object for bbox outputs\n",
        "    probs = result.probs  # Class probabilities for classification outputs\n",
        "    cls = boxes.cls.tolist()  # Convert tensor to list\n",
        "    xyxy = boxes.xyxy\n",
        "    xywh = boxes.xywh  # box with xywh format, (N, 4)\n",
        "    conf = boxes.conf\n",
        "    print(cls)\n",
        "    for class_index in cls:\n",
        "        class_name = class_names[int(class_index)]\n",
        "        print(\"Class:\", class_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "461c7b6e",
      "metadata": {
        "id": "461c7b6e"
      },
      "source": [
        "# DeepSORT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n2UVlTKmDyXs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2UVlTKmDyXs",
        "outputId": "5fc2f937-1b54-475c-e471-edcee594eb85"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "945f584b",
      "metadata": {
        "id": "945f584b"
      },
      "outputs": [],
      "source": [
        "from deep_sort.utils.parser import get_config\n",
        "from deep_sort.deep_sort import DeepSort\n",
        "from deep_sort.sort.tracker import Tracker\n",
        "\n",
        "\n",
        "deep_sort_weights = 'deep_sort/deep/checkpoint/ckpt.t7'\n",
        "tracker = DeepSort(model_path=deep_sort_weights, max_age=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "2d74f1e2",
      "metadata": {
        "id": "2d74f1e2"
      },
      "outputs": [],
      "source": [
        "# Define the video path\n",
        "video_path = 'india.MOV'\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get the video properties\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "output_path = 'output3.mp4'\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6nM6j1SvE2_J",
      "metadata": {
        "id": "6nM6j1SvE2_J"
      },
      "outputs": [],
      "source": [
        "print(cap.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "09056afd",
      "metadata": {
        "id": "09056afd"
      },
      "outputs": [],
      "source": [
        "frames = []\n",
        "\n",
        "unique_track_ids = set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "533ff5cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "533ff5cc",
        "outputId": "e072524e-af1d-4861-a2ea-13a24d1acab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<generator object BasePredictor.stream_inference at 0x000001F105162E40>\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 1 motorcycle, 140.1ms\n",
            "Speed: 0.0ms preprocess, 140.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "0\n",
            "1\n",
            "<generator object BasePredictor.stream_inference at 0x000001F105175040>\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 1 motorcycle, 137.0ms\n",
            "Speed: 0.0ms preprocess, 137.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "0\n",
            "2\n",
            "<generator object BasePredictor.stream_inference at 0x000001F105175190>\n",
            "\n",
            "0: 384x640 2 persons, 7 cars, 1 motorcycle, 124.9ms\n",
            "Speed: 0.0ms preprocess, 124.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "0\n",
            "3\n",
            "<generator object BasePredictor.stream_inference at 0x000001F1270C0040>\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 1 motorcycle, 124.2ms\n",
            "Speed: 0.0ms preprocess, 124.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "0\n",
            "4\n",
            "<generator object BasePredictor.stream_inference at 0x000001F11B05A350>\n",
            "\n",
            "0: 384x640 2 persons, 8 cars, 152.2ms\n",
            "Speed: 0.0ms preprocess, 152.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "40\n",
            "5\n",
            "<generator object BasePredictor.stream_inference at 0x000001F105162E40>\n",
            "\n",
            "0: 384x640 2 persons, 9 cars, 120.3ms\n",
            "Speed: 0.0ms preprocess, 120.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "40\n",
            "6\n",
            "<generator object BasePredictor.stream_inference at 0x000001F106BC1E40>\n",
            "\n",
            "0: 384x640 3 persons, 8 cars, 1 motorcycle, 115.8ms\n",
            "Speed: 6.3ms preprocess, 115.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "47\n",
            "7\n",
            "<generator object BasePredictor.stream_inference at 0x000001F1270F4660>\n",
            "\n",
            "0: 384x640 3 persons, 6 cars, 1 motorcycle, 111.6ms\n",
            "Speed: 0.0ms preprocess, 111.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "47\n",
            "8\n",
            "<generator object BasePredictor.stream_inference at 0x000001F11B05A350>\n",
            "\n",
            "0: 384x640 3 persons, 7 cars, 1 motorcycle, 111.5ms\n",
            "Speed: 6.5ms preprocess, 111.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "47\n",
            "9\n",
            "<generator object BasePredictor.stream_inference at 0x000001F105162E40>\n",
            "\n",
            "0: 384x640 2 persons, 7 cars, 149.5ms\n",
            "Speed: 17.2ms preprocess, 149.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "47\n",
            "10\n",
            "<generator object BasePredictor.stream_inference at 0x000001F1270F4660>\n",
            "\n",
            "0: 384x640 2 persons, 6 cars, 1 motorcycle, 116.9ms\n",
            "Speed: 0.0ms preprocess, 116.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "54\n",
            "11\n",
            "<generator object BasePredictor.stream_inference at 0x000001F106BC1E40>\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 116.9ms\n",
            "Speed: 0.0ms preprocess, 116.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "53\n",
            "12\n",
            "<generator object BasePredictor.stream_inference at 0x000001F1270C0040>\n",
            "\n",
            "0: 384x640 2 persons, 6 cars, 1 motorcycle, 128.9ms\n",
            "Speed: 0.0ms preprocess, 128.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "53\n",
            "13\n",
            "<generator object BasePredictor.stream_inference at 0x000001F105175190>\n",
            "\n",
            "0: 384x640 3 persons, 7 cars, 116.8ms\n",
            "Speed: 1.3ms preprocess, 116.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "54\n",
            "14\n",
            "<generator object BasePredictor.stream_inference at 0x000001F11B05A350>\n",
            "\n",
            "0: 384x640 3 persons, 7 cars, 183.2ms\n",
            "Speed: 0.0ms preprocess, 183.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "54\n",
            "15\n",
            "<generator object BasePredictor.stream_inference at 0x000001F1270C0120>\n",
            "\n",
            "0: 384x640 3 persons, 6 cars, 120.2ms\n",
            "Speed: 13.0ms preprocess, 120.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "54\n",
            "16\n",
            "<generator object BasePredictor.stream_inference at 0x000001F11F4CE350>\n",
            "\n",
            "0: 384x640 3 persons, 7 cars, 1 motorcycle, 172.0ms\n",
            "Speed: 11.5ms preprocess, 172.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "54\n",
            "17\n",
            "<generator object BasePredictor.stream_inference at 0x000001F106BC1E40>\n",
            "\n",
            "0: 384x640 3 persons, 6 cars, 1 motorcycle, 115.8ms\n",
            "Speed: 12.5ms preprocess, 115.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "54\n",
            "18\n",
            "<generator object BasePredictor.stream_inference at 0x000001F1270C0040>\n",
            "\n",
            "0: 384x640 4 persons, 5 cars, 1 motorcycle, 110.6ms\n",
            "Speed: 0.0ms preprocess, 110.6ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "54\n",
            "19\n",
            "<generator object BasePredictor.stream_inference at 0x000001F105175190>\n",
            "\n",
            "0: 384x640 4 persons, 7 cars, 1 motorcycle, 143.1ms\n",
            "Speed: 0.0ms preprocess, 143.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "53\n",
            "20\n",
            "<generator object BasePredictor.stream_inference at 0x000001F1270F4660>\n",
            "\n",
            "0: 384x640 4 persons, 7 cars, 1 motorcycle, 94.2ms\n",
            "Speed: 15.6ms preprocess, 94.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "54\n",
            "21\n",
            "<generator object BasePredictor.stream_inference at 0x000001F1270C0120>\n",
            "\n",
            "0: 384x640 3 persons, 7 cars, 1 motorcycle, 93.8ms\n",
            "Speed: 0.0ms preprocess, 93.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "54\n",
            "22\n",
            "<generator object BasePredictor.stream_inference at 0x000001F106BC1E40>\n",
            "\n",
            "0: 384x640 4 persons, 8 cars, 1 motorcycle, 93.8ms\n",
            "Speed: 0.0ms preprocess, 93.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "63\n",
            "23\n",
            "<generator object BasePredictor.stream_inference at 0x000001F105175190>\n",
            "\n",
            "0: 384x640 2 persons, 7 cars, 1 motorcycle, 78.1ms\n",
            "Speed: 0.0ms preprocess, 78.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "62\n",
            "24\n",
            "<generator object BasePredictor.stream_inference at 0x000001F11F4CE350>\n",
            "\n",
            "0: 384x640 2 persons, 6 cars, 1 motorcycle, 71.6ms\n",
            "Speed: 3.0ms preprocess, 71.6ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "61\n",
            "25\n",
            "<generator object BasePredictor.stream_inference at 0x000001F11F4CE430>\n",
            "\n",
            "0: 384x640 2 persons, 7 cars, 1 motorcycle, 82.2ms\n",
            "Speed: 11.9ms preprocess, 82.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "62\n",
            "26\n",
            "<generator object BasePredictor.stream_inference at 0x000001F17EBDA660>\n",
            "\n",
            "0: 384x640 2 persons, 7 cars, 99.2ms\n",
            "Speed: 0.0ms preprocess, 99.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "63\n",
            "27\n",
            "<generator object BasePredictor.stream_inference at 0x000001F1270C0040>\n",
            "\n",
            "0: 384x640 3 persons, 7 cars, 1 motorcycle, 100.5ms\n",
            "Speed: 0.0ms preprocess, 100.5ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "61\n",
            "28\n",
            "1\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "17\n",
            "20\n",
            "23\n",
            "25\n"
          ]
        }
      ],
      "source": [
        "i = 0  #moving average prediction of motion implemented linear regression commented out cus not useful\n",
        "pcount=0 #no of predicted conflict points in a frame\n",
        "counter, fps, elapsed = 0, 0, 0\n",
        "start_time = time.perf_counter()\n",
        "g_time=time.perf_counter()\n",
        "box_arrays={} #dictionary for bounding box of each id storing bounding boxes for all frames\n",
        "my_counter=0 #no of frames\n",
        "n=2 #prediction how many frames ahead, has to be small in comparison the coordinates considered for linear reg. Here we have considered only 5 coordinates so do a small no\n",
        "prediction_boxes={}\n",
        "prediction_points={}\n",
        "def estimate_coef(x, y):\n",
        "    # number of observations/points\n",
        "    n = np.size(x)\n",
        "\n",
        "    # mean of x and y vector\n",
        "    m_x = np.mean(x)\n",
        "    m_y = np.mean(y)\n",
        "\n",
        "    # calculating cross-deviation and deviation about x\n",
        "    SS_xy = np.sum(y*x) - n*m_y*m_x\n",
        "    SS_xx = np.sum(x*x) - n*m_x*m_x\n",
        "\n",
        "    # calculating regression coefficients\n",
        "    b_1 = SS_xy / SS_xx\n",
        "    b_0 = m_y - b_1*m_x\n",
        "\n",
        "    return (b_0, b_1)\n",
        "\n",
        "while cap.isOpened():\n",
        "\n",
        "\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "      cap.release()\n",
        "    if ret:\n",
        "\n",
        "        og_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frame = og_frame.copy()\n",
        "\n",
        "        model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "\n",
        "        results = model(frame, device, classes=(0,1,2,3,5,7), conf=0.5)\n",
        "\n",
        "        class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
        "\n",
        "        print(results)\n",
        "        for result in results:\n",
        "            boxes = result.boxes  # Boxes object for bbox outputs\n",
        "            probs = result.probs  # Class probabilities for classification outputs\n",
        "            cls = boxes.cls.tolist()  # Convert tensor to list\n",
        "            xyxy = boxes.xyxy\n",
        "            conf = boxes.conf\n",
        "            xywh = boxes.xywh  # box with xywh format, (N, 4)\n",
        "            for class_index in cls:\n",
        "                class_name = class_names[int(class_index)]\n",
        "                #print(\"Class:\", class_name)\n",
        "\n",
        "        pred_cls = np.array(cls)\n",
        "        conf = conf.detach().cpu().numpy()\n",
        "        xyxy = xyxy.detach().cpu().numpy()\n",
        "        bboxes_xywh = xywh\n",
        "        bboxes_xywh = xywh.cpu().numpy()\n",
        "        bboxes_xywh = np.array(bboxes_xywh, dtype=float)\n",
        "\n",
        "        tracks = tracker.update(bboxes_xywh, conf, og_frame)\n",
        "\n",
        "        for track in tracker.tracker.tracks:\n",
        "            track_id = track.track_id\n",
        "            hits = track.hits\n",
        "            x1, y1, x2, y2 = track.to_tlbr()  # Get bounding box coordinates in (x1, y1, x2, y2) format\n",
        "            w = x2 - x1  # Calculate width\n",
        "            h = y2 - y1  # Calculate height\n",
        "\n",
        "            if track_id in box_arrays:\n",
        "              box_arrays[track_id].append([x1,y1,w,h])\n",
        "            else:\n",
        "              box_arrays[track_id]=[]\n",
        "              box_arrays[track_id].append([x1,y1,w,h])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Set color values for red, blue, and green\n",
        "            red_color = (0, 0, 255)  # (B, G, R)\n",
        "            blue_color = (255, 0, 0)  # (B, G, R)\n",
        "            green_color = (0, 255, 0)  # (B, G, R)\n",
        "\n",
        "            # Determine color based on track_id\n",
        "            color_id = track_id % 3\n",
        "            if color_id == 0:\n",
        "                color = red_color\n",
        "            elif color_id == 1:\n",
        "                color = blue_color\n",
        "            else:\n",
        "                color = green_color\n",
        "\n",
        "            cv2.rectangle(og_frame, (int(x1+w/2), int(y1+h/2)), (int(x1 + w/2+2), int(y1 + h/2+2)), color, 2) \n",
        "            cv2.rectangle(og_frame, (int(x1), int(y1)), (int(x1 + w), int(y1 + h)), color, 2) \n",
        "            text_color = (0, 0, 0)  # Black color for text\n",
        "            cv2.putText(og_frame, f\"{class_name}-{track_id}\", (int(x1) + 10, int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
        "\n",
        "            # Add the track_id to the set of unique track IDs\n",
        "            unique_track_ids.add(track_id)\n",
        "\n",
        "        for id in box_arrays:\n",
        "              cid = id % 3\n",
        "              if cid == 0:\n",
        "                color = red_color\n",
        "              elif cid == 1:\n",
        "                color = blue_color\n",
        "              else:\n",
        "                color = green_color\n",
        "\n",
        "              if len(box_arrays[id])>=5:\n",
        "               x12=np.array([box_arrays[id][len(box_arrays[id])-5][0],box_arrays[id][len(box_arrays[id])-4][0],box_arrays[id][len(box_arrays[id])-3][0],box_arrays[id][len(box_arrays[id])-2][0],box_arrays[id][len(box_arrays[id])-1][0]])\n",
        "               y12=np.array([box_arrays[id][len(box_arrays[id])-5][1],box_arrays[id][len(box_arrays[id])-4][1],box_arrays[id][len(box_arrays[id])-3][1],box_arrays[id][len(box_arrays[id])-2][1],box_arrays[id][len(box_arrays[id])-1][1]])\n",
        "               w2=np.array([box_arrays[id][len(box_arrays[id])-5][2],box_arrays[id][len(box_arrays[id])-4][2],box_arrays[id][len(box_arrays[id])-3][2],box_arrays[id][len(box_arrays[id])-2][2],box_arrays[id][len(box_arrays[id])-1][2]])\n",
        "               h2=np.array([box_arrays[id][len(box_arrays[id])-5][3],box_arrays[id][len(box_arrays[id])-4][3],box_arrays[id][len(box_arrays[id])-3][3],box_arrays[id][len(box_arrays[id])-2][3],box_arrays[id][len(box_arrays[id])-1][3]])\n",
        "               c=np.array([1,2,3,4,5])\n",
        "\n",
        "               ax12,bx12=estimate_coef(c,x12) #Y=a+bX\n",
        "               ay12,by12=estimate_coef(c,y12)\n",
        "               aw2,bw2=estimate_coef(c,w2)\n",
        "               ah2,bh2=estimate_coef(c,h2)\n",
        "\n",
        "               if id in prediction_boxes:\n",
        "                  prediction_boxes[id]=[ax12+bx12*(5+n),ay12+by12*(5+n),aw2+bw2*(5+n),ah2+bh2*(5+n)]\n",
        "               else:\n",
        "                  prediction_boxes[id]=[]\n",
        "                  prediction_boxes[id]=[ax12+bx12*(5+n),ay12+by12*(5+n),aw2+bw2*(5+n),ah2+bh2*(5+n)]\n",
        "\n",
        "               #cv2.rectangle(og_frame, (int(prediction_boxes[id][0]), int(prediction_boxes[id][1])), (int(prediction_boxes[id][0] + prediction_boxes[id][2]), int(prediction_boxes[id][1] + prediction_boxes[id][3])), color, 2)\n",
        "        for id in prediction_boxes:\n",
        "           if id in prediction_points:\n",
        "            \n",
        "            prediction_points[id]=[int(prediction_boxes[id][0] + prediction_boxes[id][2]/2), int(prediction_boxes[id][1] + prediction_boxes[id][3]/2)]\n",
        "           else:\n",
        "              prediction_points[id]=[]\n",
        "              prediction_points[id]=[int(prediction_boxes[id][0] + prediction_boxes[id][2]/2), int(prediction_boxes[id][1] + prediction_boxes[id][3]/2)]\n",
        "        \n",
        "        for ip in range(0,len(prediction_points)):\n",
        "           for kip in range(ip, len(prediction_points)):\n",
        "              xx1=prediction_points[list(prediction_points.keys())[ip]][0]\n",
        "              xx2=prediction_points[list(prediction_points.keys())[kip]][0]\n",
        "              yy1=prediction_points[list(prediction_points.keys())[ip]][1]\n",
        "              yy2=prediction_points[list(prediction_points.keys())[kip]][1]\n",
        "              \n",
        "              if int(((xx1-xx2)^2+(yy1-yy2)^2))<1: # 1 is the distance between two predicted points for them to be in conflict\n",
        "                 cv2.rectangle(og_frame, (int((xx1+xx2)/2), int((yy1+yy2)/2)), (int((xx1+xx2)/2), int((yy1+yy2)/2)), color, 2)\n",
        "                 pcount+=1\n",
        "                 \n",
        "                 \n",
        "\n",
        "        print(pcount)\n",
        "        # Update the person count based on the number of unique track IDs\n",
        "        person_count = len(unique_track_ids)\n",
        "        pcount=0\n",
        "        # Update FPS and place on frame\n",
        "        current_time = time.perf_counter()\n",
        "        elapsed = (current_time - start_time)\n",
        "        counter += 1\n",
        "        if elapsed > 1:\n",
        "            fps = counter / elapsed\n",
        "            counter = 0\n",
        "            start_time = current_time\n",
        "\n",
        "        my_counter+=1\n",
        "        print(my_counter)\n",
        "\n",
        "\n",
        "        # Draw person count on frame\n",
        "        cv2.putText(og_frame, f\"Person Count: {person_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        # Append the frame to the list\n",
        "        frames.append(og_frame)\n",
        "\n",
        "        # Write the frame to the output video file\n",
        "        out.write(cv2.cvtColor(og_frame, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "\n",
        "        if (current_time-g_time)>60:\n",
        "          cap.release()\n",
        "        # Show the frame\n",
        "        #cv2.imshow(\"Video\", og_frame)\n",
        "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "#             break\n",
        "\n",
        "\n",
        "for i in tracker.tracker.tracks:\n",
        "  print(i.track_id)\n",
        "cap.release()\n",
        "out.release()\n",
        "#cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
